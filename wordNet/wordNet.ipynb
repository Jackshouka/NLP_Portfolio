{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WordNet\n",
    "### Summary\n",
    "WordNet is something akin to a dictionary. It is a database that houses nouns, adjectives, verbs and adverbs that all come with something called 'glosses'. These are short definitions of the word. Additionally, WordNet also provides synsets, a set of synonyms for a certain word. WordNet has it's own hierarchical design due to it's beginnings as a way to support theroies over human semantic memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('house.n.01'),\n",
       " Synset('firm.n.01'),\n",
       " Synset('house.n.03'),\n",
       " Synset('house.n.04'),\n",
       " Synset('house.n.05'),\n",
       " Synset('house.n.06'),\n",
       " Synset('house.n.07'),\n",
       " Synset('sign_of_the_zodiac.n.01'),\n",
       " Synset('house.n.09'),\n",
       " Synset('family.n.01'),\n",
       " Synset('theater.n.01'),\n",
       " Synset('house.n.12'),\n",
       " Synset('house.v.01'),\n",
       " Synset('house.v.02')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import wordnet and select a noun. Output all sysnsets\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('house')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('house.n.09')\n",
      "[Lemma('house.n.09.house')]\n",
      "['the house gets a percentage of every bet']\n",
      "the management of a gambling house or casino None None\n",
      "\n",
      "\n",
      "Hypernyms of House (casino): \n",
      "management.n.02\n",
      "administration.n.02\n",
      "body.n.02\n",
      "social_group.n.01\n",
      "group.n.01\n",
      "abstraction.n.06\n",
      "entity.n.01\n",
      "Hyponyms of House (casino): \n",
      "Meronyms of House (casino): \n",
      "Holonyms of House (casino): \n",
      "Antonyms of House (casino): \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Synset('good.n.01'),\n",
       " Synset('good.n.02'),\n",
       " Synset('good.n.03'),\n",
       " Synset('commodity.n.01'),\n",
       " Synset('good.a.01'),\n",
       " Synset('full.s.06'),\n",
       " Synset('good.a.03'),\n",
       " Synset('estimable.s.02'),\n",
       " Synset('beneficial.s.01'),\n",
       " Synset('good.s.06'),\n",
       " Synset('good.s.07'),\n",
       " Synset('adept.s.01'),\n",
       " Synset('good.s.09'),\n",
       " Synset('dear.s.02'),\n",
       " Synset('dependable.s.04'),\n",
       " Synset('good.s.12'),\n",
       " Synset('good.s.13'),\n",
       " Synset('effective.s.04'),\n",
       " Synset('good.s.15'),\n",
       " Synset('good.s.16'),\n",
       " Synset('good.s.17'),\n",
       " Synset('good.s.18'),\n",
       " Synset('good.s.19'),\n",
       " Synset('good.s.20'),\n",
       " Synset('good.s.21'),\n",
       " Synset('well.r.01'),\n",
       " Synset('thoroughly.r.02')]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#select a synset and go up the hierarchy\n",
    "noun = wn.synset('house.n.09')\n",
    "print(noun)\n",
    "print(noun.definition(),\n",
    "print(noun.lemmas()),\n",
    "print(noun.examples()))\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Hypernyms of House (casino): \", )\n",
    "hypernyms = noun.hypernyms()\n",
    "while hypernyms:\n",
    "    print(hypernyms[0].name())\n",
    "    hypernyms = hypernyms[0].hypernyms()\n",
    "\n",
    "print(\"Hyponyms of House (casino): \", )\n",
    "hyponyms = noun.hyponyms()\n",
    "for hyponym in hyponyms:\n",
    "    print(hyponym.name())\n",
    "\n",
    "print(\"Meronyms of House (casino): \", )\n",
    "meronyms = noun.part_meronyms()\n",
    "for meronym in meronyms:\n",
    "    print(meronym.name())\n",
    "\n",
    "print(\"Holonyms of House (casino): \", )\n",
    "holonyms = noun.part_holonyms()\n",
    "for holonym in holonyms:\n",
    "    print(holonym.name())\n",
    "\n",
    "print(\"Antonyms of House (casino): \", )\n",
    "#lemmatize\n",
    "lemmas = noun.lemmas()\n",
    "for lemma in lemmas:\n",
    "    antonyms = lemma.antonyms()\n",
    "    if antonyms:\n",
    "        for antonym in antonyms:\n",
    "            print(antonym.name())\n",
    "\n",
    "\n",
    "\n",
    "wn.synsets('good')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown here, we can see that traversing up the WordNet hierarchy will get us more general synsets as we move up. We started with 'house', in this case refering to the casino (\"The house always wins!\") and as we traversed up the hierarchy we can to see synsets like management, from management we went to administration and so on. So WordNet tries to be as broad and inclusive as possible.\n",
    "\n",
    "That synset of house isn't great for hyponyms, meronyms, etc. So we'll try a different noun and see what comes up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyponyms of Good: \n",
      "beneficence.n.02\n",
      "benignity.n.01\n",
      "kindness.n.01\n",
      "saintliness.n.01\n",
      "summum_bonum.n.01\n",
      "virtue.n.01\n",
      "virtue.n.04\n",
      "\n",
      "\n",
      "Meronyms of Good: \n",
      "\n",
      "\n",
      "Holonyms of Good: \n",
      "\n",
      "\n",
      "Antonyms of Good: \n",
      "evil\n",
      "evilness\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_noun = wn.synset('good.n.02')\n",
    "\n",
    "print(\"Hyponyms of Good: \", )\n",
    "hyponyms = new_noun.hyponyms()\n",
    "for hyponym in hyponyms:\n",
    "    print(hyponym.name())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Meronyms of Good: \", )\n",
    "meronyms = new_noun.part_meronyms()\n",
    "for meronym in meronyms:\n",
    "    print(meronym.name())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Holonyms of Good: \", )\n",
    "holonyms = new_noun.part_holonyms()\n",
    "for holonym in holonyms:\n",
    "    print(holonym.name())\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Antonyms of Good: \", )\n",
    "#lemmatize\n",
    "lemmas = new_noun.lemmas()\n",
    "for lemma in lemmas:\n",
    "    antonyms = lemma.antonyms()\n",
    "    if antonyms:\n",
    "        for antonym in antonyms:\n",
    "            print(antonym.name())\n",
    "print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('eat.v.01'), Synset('eat.v.02'), Synset('feed.v.06'), Synset('eat.v.04'), Synset('consume.v.05'), Synset('corrode.v.01')]\n"
     ]
    }
   ],
   "source": [
    "#selecting a verb\n",
    "verb = wn.synsets('eat')\n",
    "print(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('consume.v.05')\n",
      "[Lemma('consume.v.05.consume'), Lemma('consume.v.05.eat_up'), Lemma('consume.v.05.use_up'), Lemma('consume.v.05.eat'), Lemma('consume.v.05.deplete'), Lemma('consume.v.05.exhaust'), Lemma('consume.v.05.run_through'), Lemma('consume.v.05.wipe_out')]\n",
      "['this car consumes a lot of gas', 'We exhausted our savings', 'They run through 20 bottles of wine a week']\n",
      "use up (resources or materials) None None\n",
      "\n",
      "\n",
      "Hypernyms of Consume: \n",
      "spend.v.02\n",
      "pay.v.01\n",
      "give.v.03\n",
      "transfer.v.05\n"
     ]
    }
   ],
   "source": [
    "#extracting everything from verb = CONSUME\n",
    "verb = wn.synset('consume.v.05')\n",
    "print(verb)\n",
    "print(verb.definition(),\n",
    "print(verb.lemmas()),\n",
    "print(verb.examples()))\n",
    "print(\"\\n\")\n",
    "\n",
    "#traversing up the hierarchy\n",
    "print(\"Hypernyms of Consume: \", )\n",
    "hypernyms = verb.hypernyms()\n",
    "while hypernyms:\n",
    "    print(hypernyms[0].name())\n",
    "    hypernyms = hypernyms[0].hypernyms()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WordNet's hierarchy of verbs is similar from how it organizes nouns, as it looks for common verbs while looking to get more broad and general. At the top of the WordNet verb hierarchy, we have really broad categories and the goal is to get closer to those broad categories as we traverse the hierarchy. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "consume\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#morphy\n",
    "print(wn.morphy(\"consume\", wn.ADJ))\n",
    "print(wn.morphy(\"consume\", wn.VERB))\n",
    "print(wn.morphy(\"consume\", wn.NOUN))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Staying on topic here, we'll evaluate how similar the words 'consume' and 'eat' are to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8571428571428571\n",
      "Synset('eat.v.02')\n",
      "Synset('consume.v.02')\n",
      "eat a meal; take a meal\n",
      "serve oneself to, or consume regularly\n"
     ]
    }
   ],
   "source": [
    "eat = wn.synset('eat.v.01')\n",
    "consume = wn.synset('consume.v.01') #different defn: meaning eat immoderately\n",
    "\n",
    "print(wn.wup_similarity(eat, consume))\n",
    "\n",
    "#lesk\n",
    "from nltk.wsd import lesk\n",
    "\n",
    "sent = ['I', 'will', 'eat', 'grass']\n",
    "sent2 = ['Thier', 'cheif', 'food', 'is', 'grass', 'but', 'they', 'also', 'consume', 'large', 'amounts', 'of', 'LOUD', 'ROOMMATES.']\n",
    "print(lesk(sent, 'eat'))\n",
    "print(lesk(sent2, 'consume'))\n",
    "\n",
    "eatv2 = wn.synset('eat.v.02')\n",
    "consumev2 = wn.synset('consume.v.02')\n",
    "\n",
    "print(eatv2.definition())\n",
    "print(consumev2.definition())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the Wu-Palmer rated 'eat' and 'consume' as very similar, which is what I expected. Though the lesk algorithm detected different versions of the original verbs, which I didn't expect as much. Maybe my sample sentences aren't great to use here, as eat/consume can become pretty ambiguous depending on what you're talking about."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiwordnet is used to assign WordNet synsets values that range from positive, negative and neutral. THis is typically referred to as sentiment analysis and has some interesting use cases. One potential use case I would think is particularly useful is scraping off of Twitter to find public opinon on certain companies to try and make a stock suggestion tool, however the depression detection in tweets example we discussed in class seems to be an infinitly more useful use case than anything I can think of, in my opinion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<rain.n.01: PosScore=0.0 NegScore=0.0>\n",
      "Positive score =  0.0\n",
      "Negative score =  0.0\n",
      "Objective score =  1.0\n",
      "Positive: 0.0\n",
      "Negative: 0.625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     /home/jacko/nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import sentiwordnet as swn\n",
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "\n",
    "rain = swn.senti_synset('rain.n.01')\n",
    "print(rain)\n",
    "print(\"Positive score = \", rain.pos_score())\n",
    "print(\"Negative score = \", rain.neg_score())\n",
    "print(\"Objective score = \", rain.obj_score())\n",
    "\n",
    "sentence = 'Do not rain on my parade'\n",
    "pos = 0\n",
    "neg = 0\n",
    "tokens = sentence.split()\n",
    "\n",
    "for token in tokens:\n",
    "    syn_list = list(swn.senti_synsets(token))\n",
    "    if syn_list:\n",
    "        syn = syn_list[0]\n",
    "        neg += syn.neg_score()\n",
    "        pos += syn.pos_score()\n",
    "\n",
    "print('Positive:', pos)\n",
    "print('Negative:', neg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a more negative score when we evalute the whole sentence, which I'm betting is exclusively because of the word \"NOT\" in the phrase \"Do not rain on my parade\", which makes sense, as rain isn't inherently bad or good when talking about the weather, I guess."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collactions are when words appear together and it is determined that this is down to more than chance, meaning that those words share some kind of relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "United States; fellow citizens; years ago; four years; Federal\n",
      "Government; General Government; American people; Vice President; God\n",
      "bless; Chief Justice; one another; fellow Americans; Old World;\n",
      "Almighty God; Fellow citizens; Chief Magistrate; every citizen; Indian\n",
      "tribes; public debt; foreign nations\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.book import text4\n",
    "\n",
    "text4.collocations()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to focus on 'fellow citizens' just because it's the first one and said a lot in every day speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p(Fellow - Citizens):  0.0004987531172069825\n",
      "p(Fellow):  0.002394014962593516\n",
      "p(Citizens):  0.0006982543640897755\n",
      "PMI:  8.220925288338247\n"
     ]
    }
   ],
   "source": [
    "text = ' '.join(text4.tokens)\n",
    "\n",
    "import math\n",
    "vocab = len(set(text4))\n",
    "hg = text.count('Fellow - Citizens')/vocab\n",
    "print(\"p(Fellow - Citizens): \", hg)\n",
    "h = text.count('Fellow')/vocab\n",
    "print(\"p(Fellow): \", h)\n",
    "g =text.count('Citizens')/vocab\n",
    "print(\"p(Citizens): \", g)\n",
    "pmi = math.log2(hg/(h*g))\n",
    "print(\"PMI: \", pmi)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our PMI is really high! This means that we can conclude that \"Fellow Citizens\" is very likely to be a collocation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
